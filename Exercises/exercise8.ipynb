{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 8 - Bootstrap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1 - exercise 13 from chapter 8\n",
    "\n",
    "In the bootstrap method we are given a sequence of $n$ datapoints and we then sample from this sequence using sampling with replacement to generate a bootstrap set $B_i$. In practice we might generate a large number of bootstrap set which we use to infer important statistical properties of our original data sequence.\n",
    "\n",
    "In the exercise we have $n$ iid random variables with unknowns mean $\\mu$ and two constants $a<b$. We aim to estimate $$p=P\\left\\{a<\\sum_{i=1}^n X_i / n-\\mu<b\\right\\}$$\n",
    "\n",
    "We do that by generating $K$ bootstrap sets where each set has $n$ values. For each bootstrap set $B_i, i \\in \\{1,..,K\\}$ we then compute the mean, $B_{means} := \\mathbb{E}[B_i]$. Then we define a new variable\n",
    "$$\n",
    "Z := B_{means} - \\mathbb{E}[{B_{means}}]\n",
    "$$\n",
    "where $\\mathbb{E}[{B_{means}}]$ is out estimate of $\\mu$. \n",
    "\n",
    "Hence, $Z = \\sum_{i=1}^n X_i / n-\\mu$\n",
    "\n",
    "So, finally we evaluate $p_m = p(a < Z< b) = \\frac{\\sum(\\mathbb{I}({a<z_i<b}))}{K}, \\forall i \\in {1,..,K}$. To ensure a robust estimate, we repeat this procedure $M$ times, such that our final estimate becomes\n",
    "\n",
    "$$\n",
    "p = \\mathbb{E}[p_m]\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([56,101,78,67,93,87,64,72,80,69])\n",
    "a,b=-5,5\n",
    "\n",
    "n = len(X) # size of each bootstrap set\n",
    "K = 100 #number of bootstrap sets to produce\n",
    "M = 100 # repitions of bootstrap procedure\n",
    "\n",
    "bootstrap_samples = np.random.choice(X,replace=True,size=n*K*M).reshape(M,K,n)\n",
    "B_i_means = bootstrap_samples.mean(-1)\n",
    "Z = B_i_means - B_i_means.mean(-1)\n",
    "prop_i = ((a<Z)&(Z<b)).mean(-1)\n",
    "p = prop_i.mean()\n",
    "print(f\"Estimate of p using n={n}, K={K}, M={M} is: {p}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A confidence interval of this estimate is then"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p+np.array([-1,1])*1.96*np.sqrt(np.var(prop_i)/M)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2 - Exercise 15 from chapter 8\n",
    "\n",
    "We are now given some new data, where $n=15$ and we want to estimate $Var(S^2)$ where $S^2$ is the sample variance.\n",
    "We follow the same procedure as above, however for each $B_i$ we instead estimate the variance, $B_{var}:=Var[B_i]$ and then the variance of $B_{var}$, $Var[B_{var}]$, before finally returning the estimate $\\mathbb{E}[Var[B_{var}]]$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([5, 4, 9, 6, 21, 17, 11, 20, 7, 10, 21, 15, 13, 16, 8])\n",
    "\n",
    "n = len(X) # size of each bootstrap set\n",
    "K = 100 #number of bootstrap sets to produce\n",
    "M = 100 # repitions of bootstrap procedure\n",
    "\n",
    "bootstrap_samples = np.random.choice(X,replace=True,size=n*K*M).reshape(M,K,n)\n",
    "B_i_var = bootstrap_samples.var(-1,ddof=1)\n",
    "var_i = np.var(B_i_var,-1,ddof=1)\n",
    "var_s2 = np.mean(var_i)\n",
    "\n",
    "print(f\"Var(S^2) = {var_s2}\")\n",
    "\n",
    "\n",
    "print(f\"CI: {var_s2+np.array([-1,1])*1.96*np.sqrt(np.var(var_i)/M)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3- \n",
    "We now sample 200 samples from a pareto distribution with $\\beta=1$ $k=1.05$ and generate bootsrap etimates of the variance of the median and mean."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bootstrap_sim(X,n,M,K,type_:str='median'):\n",
    "    bootstrap_samples = np.random.choice(X,replace=True,size=n*K*M).reshape(M,K,n)\n",
    "    if type_ == 'median':\n",
    "        b_i_agg = np.median(bootstrap_samples,-1)\n",
    "        b_agg = np.var(b_i_agg,-1,ddof=1)\n",
    "        estimate = np.mean(b_agg)\n",
    "    elif type_ == 'mean':\n",
    "        b_i_agg = np.mean(bootstrap_samples,-1)\n",
    "        b_agg = np.var(b_i_agg,-1,ddof=1)\n",
    "        estimate = np.mean(b_agg)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"type = {type_} is not implemented\")\n",
    "\n",
    "    print(f\"Estimate of {type_} is: {estimate}\")\n",
    "    print(f\"CI: {estimate + np.array([-1,1])*1.96*np.sqrt(np.var(b_agg)/M)}\")\n",
    "    #return estimate\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 200\n",
    "pareto_samples = stats.pareto.rvs(1.05,scale=1,size=N)\n",
    "\n",
    "print(f\"Sample mean of pareto samples is: {np.mean(pareto_samples)}\")\n",
    "print(f\"Sample median of pareto samples is: {np.median(pareto_samples)}\\n\")\n",
    "\n",
    "bootstrap_sim(X=pareto_samples,n=N,M=100,K=100,type_='median')\n",
    "print(\"\")\n",
    "bootstrap_sim(X=pareto_samples,n=N,M=100,K=100,type_='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the estimate of the variance of the median is more stable compared to the variance of the mean of the bootstrap estimates based on the confidence interval is more tight for the median. We know that for small $k$ close to 1 the Pareto distribution can take values that are very large outliers and hence disturb the mean and force it towards a higher value. Whereas the median is more robust towards such outliers, why we observe the above phenomonen, "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the estimate of the variance of the median is more stable compared to the variance of the mean of the bootstrap estimates based on the confidence interval is more tight for the median. We know that for small $k$ close to 1 the Pareto distribution can take values that are very large outliers and hence disturb the mean and force it towards a higher value. Whereas the median is more robust towards such outliers, why we observe the above phenomonen, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}